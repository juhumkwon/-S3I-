{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMb6fGyrhv2FKChlIY9E0S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juhumkwon/-S3I-/blob/main/CL_04_00_%EB%94%A5%EB%9F%AC%EB%8B%9D_%ED%95%99%EC%8A%B5%EA%B3%BC%EC%A0%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57Pc8tvGiyDk",
        "outputId": "3c941d4d-21cc-4afd-a78b-eef235281c79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Loss = 0.1046, W = 2.0924, b = 0.5380\n",
            "Epoch 20: Loss = 0.0189, W = 2.1099, b = 0.6733\n",
            "Epoch 30: Loss = 0.0103, W = 2.0819, b = 0.7592\n",
            "Epoch 40: Loss = 0.0056, W = 2.0604, b = 0.8223\n",
            "Epoch 50: Loss = 0.0031, W = 2.0446, b = 0.8689\n",
            "Epoch 60: Loss = 0.0017, W = 2.0329, b = 0.9033\n",
            "Epoch 70: Loss = 0.0009, W = 2.0243, b = 0.9286\n",
            "Epoch 80: Loss = 0.0005, W = 2.0179, b = 0.9473\n",
            "Epoch 90: Loss = 0.0003, W = 2.0132, b = 0.9611\n",
            "Epoch 100: Loss = 0.0001, W = 2.0098, b = 0.9713\n",
            "\n",
            "최종 학습된 모델: y = 2.01x + 0.97\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# ----------------------\n",
        "# 1. 데이터 (y = 2x + 1 관계를 학습)\n",
        "# ----------------------\n",
        "x_data = np.array([[1.0], [2.0], [3.0], [4.0]], dtype=np.float32)\n",
        "y_data = np.array([[3.0], [5.0], [7.0], [9.0]], dtype=np.float32)\n",
        "\n",
        "# ----------------------\n",
        "# 2. 모델 파라미터 (학습 대상)\n",
        "# ----------------------\n",
        "W = tf.Variable(tf.random.normal([1, 1]))\n",
        "b = tf.Variable(tf.random.normal([1]))\n",
        "\n",
        "# ----------------------\n",
        "# 3. 학습 하이퍼파라미터\n",
        "# ----------------------\n",
        "learning_rate = 0.1\n",
        "epochs = 100\n",
        "\n",
        "# ----------------------\n",
        "# 4. 학습 루프\n",
        "# ----------------------\n",
        "for epoch in range(epochs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # (1) 순전파: y_pred = W * x + b\n",
        "        y_pred = tf.matmul(x_data, W) + b\n",
        "\n",
        "        # (2) 손실함수: MSE\n",
        "        loss = tf.reduce_mean(tf.square(y_data - y_pred))\n",
        "\n",
        "    # (3) 기울기 계산 (역전파)\n",
        "    dW, db = tape.gradient(loss, [W, b])\n",
        "\n",
        "    # (4) 파라미터 업데이트 (경사하강법)\n",
        "    W.assign_sub(learning_rate * dW)\n",
        "    b.assign_sub(learning_rate * db)\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}: Loss = {loss.numpy():.4f}, W = {W.numpy()[0][0]:.4f}, b = {b.numpy()[0]:.4f}\")\n",
        "\n",
        "# ----------------------\n",
        "# 5. 최종 결과 확인\n",
        "# ----------------------\n",
        "print(\"\\n최종 학습된 모델: y = {:.2f}x + {:.2f}\".format(W.numpy()[0][0], b.numpy()[0]))\n"
      ]
    }
  ]
}